import streamlit as st
import os
import itertools
import time
import base64
from dotenv import load_dotenv
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from qdrant_client import QdrantClient
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage

# 1. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
QDRANT_URL = os.getenv("QDRANT_URL")
QDRANT_API_KEY = os.getenv("QDRANT_API_KEY")
COLLECTION_NAME = "love_counseling_db"

# 2. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ì—°ì•  ìƒë‹´ì†Œ", page_icon="â¤ï¸", layout="wide")

# ğŸš€ ì†ë„ ê°œì„ : ì´ë¯¸ì§€ ìºì‹±
@st.cache_data
def get_image_base64(path):
    if not os.path.exists(path): return ""
    with open(path, "rb") as f:
        data = f.read()
    return base64.b64encode(data).decode()

# ğŸš€ ì†ë„ ê°œì„ : Qdrant í´ë¼ì´ì–¸íŠ¸ ë° Embeddings ìºì‹±
@st.cache_resource
def get_qdrant_client():
    return QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)

@st.cache_resource
def get_embeddings():
    return OpenAIEmbeddings(model="text-embedding-3-small", openai_api_key=OPENAI_API_KEY)

# ğŸ¨ CSS ì„¤ì • (ìš°ì„ ìˆœìœ„ ê°•í™” ë²„ì „)
st.markdown(f"""
    <style>
    .stApp {{ background-color: #F5F2F2; }}
    h1, h2, h3 {{ color: #333333 !important; text-align: center; }}
    
    /* ì•„ë°”íƒ€ ìˆ¨ê¸°ê¸° */
    [data-testid="stChatMessageAvatarAssistant"], 
    [data-testid="stChatMessageAvatarUser"] {{ 
        display: none !important; 
    }}
    
    /* ëª¨ë“  ì±„íŒ… ë©”ì‹œì§€ ê¸°ë³¸ ìŠ¤íƒ€ì¼ */
    [data-testid="stChatMessage"] {{
        border-radius: 20px; 
        padding: 10px 15px; 
        margin-bottom: 20px; 
        display: flex !important;
    }}

    /* ğŸ‘¤ ì‚¬ìš©ì ëŒ€í™”ì°½ (ì˜¤ë¥¸ìª½ ë°°ì¹˜ + ë¸”ë£¨ ë°°ê²½ + ê¸€ì í°ìƒ‰) */
    .stChatMessage[aria-label="user"] {{
        background-color: #5A7ACD !important;
        margin-left: auto !important;
        margin-right: 0 !important;
        flex-direction: row-reverse !important;
        width: fit-content !important;
        max-width: 80% !important;
    }}
    
    /* user role ì„ íƒì ì¶”ê°€ (Streamlit ë²„ì „ í˜¸í™˜) */
    [data-testid="stChatMessage"]:has([data-testid="stChatMessageAvatarUser"]) {{
        background-color: #5A7ACD !important;
        margin-left: auto !important;
        margin-right: 0 !important;
        flex-direction: row-reverse !important;
        width: fit-content !important;
        max-width: 80% !important;
    }}

    /* ì‚¬ìš©ì ì°½ ë‚´ë¶€ í…ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼ */
    .stChatMessage[aria-label="user"] .stMarkdown p,
    .stChatMessage[aria-label="user"] .stMarkdown span,
    .stChatMessage[aria-label="user"] p,
    [data-testid="stChatMessage"]:has([data-testid="stChatMessageAvatarUser"]) .stMarkdown p,
    [data-testid="stChatMessage"]:has([data-testid="stChatMessageAvatarUser"]) p {{
        color: #FFFFFF !important;
        text-align: right !important;
        font-weight: 500 !important;
    }}

    /* ğŸ¤– í•˜íŠ¸ ë°•ì‚¬ë‹˜ ëŒ€í™”ì°½ (ì™¼ìª½ ë°°ì¹˜ + ë…¸ë€ìƒ‰ ë°°ê²½) */
    .stChatMessage[aria-label="assistant"],
    [data-testid="stChatMessage"]:has([data-testid="stChatMessageAvatarAssistant"]) {{
        background-color: #FFC50F !important;
        margin-right: auto !important;
        margin-left: 0 !important;
        width: 100% !important;
    }}
    
    .stChatMessage[aria-label="assistant"] .stMarkdown p,
    .stChatMessage[aria-label="assistant"] .stMarkdown span,
    .stChatMessage[aria-label="assistant"] p,
    [data-testid="stChatMessage"]:has([data-testid="stChatMessageAvatarAssistant"]) .stMarkdown p,
    [data-testid="stChatMessage"]:has([data-testid="stChatMessageAvatarAssistant"]) p {{
        color: #333333 !important;
        font-size: 18px !important;
        font-weight: 600 !important;
    }}

    img {{ border-radius: 0px !important; }}

    .intro-overlay {{
        position: fixed; top: 0; left: 0; width: 100vw; height: 100vh;
        background-color: #F5F2F2; display: flex; flex-direction: column;
        align-items: center; justify-content: center; z-index: 999999;
    }}
    </style>
    """, unsafe_allow_html=True)

# âœ¨ 3. ì¸íŠ¸ë¡œ ì• ë‹ˆë©”ì´ì…˜ (ì´í•˜ ë™ì¼ ë¡œì§)
if "intro_done" not in st.session_state:
    st.session_state.intro_done = False

if not st.session_state.intro_done:
    intro_placeholder = st.empty()
    welcome_text = "ë°˜ê°€ì›Œìš”! í•˜íŠ¸ ë°•ì‚¬ê°€ ê¸°ë‹¤ë¦¬ê³  ìˆì—ˆì–´ìš”â¤ï¸"
    img_files = ["assets/heart_o.png", "assets/heart_a.png", "assets/heart_closed.png"]
    img_data = [get_image_base64(f) for f in img_files]
    mouth_cycle = itertools.cycle(img_data)
    typed_text = ""
    for char in welcome_text:
        typed_text += char
        with intro_placeholder.container():
            st.markdown(f'<div class="intro-overlay"><img src="data:image/png;base64,{next(mouth_cycle)}" style="width:350px;"><div style="background:#F5F2F2; padding:20px; border-radius:40px; color:#333333; font-size:26px; font-weight:bold; box-shadow:0 10px 25px rgba(0,0,0,0.3);">{typed_text}</div></div>', unsafe_allow_html=True)
        time.sleep(0.08)
    st.session_state.intro_done = True
    st.rerun()

# --- 4. ë³¸ í™”ë©´ ---
st.markdown("<h1 style='color: #333333 !important;'>â¤ï¸ ì—°ì•  ìƒë‹´ì†Œ â¤ï¸</h1>", unsafe_allow_html=True)
st.markdown("---")

if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "í•˜íŠ¸ ë°•ì‚¬ì˜ˆìš”. ì˜¤ëŠ˜ ì–´ë–¤ ë§ˆìŒì˜ ê³ ë¯¼ì„ ë“¤ê³  ì™”ì„ê¹Œìš”?"}]

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        if message["role"] == "assistant":
            col1, col2 = st.columns([1, 4])
            with col1: st.image("assets/heart_closed.png", width=120)
            with col2: st.markdown(f"<p>{message['content']}</p>", unsafe_allow_html=True)
        else:
            # ì‚¬ìš©ì ë©”ì‹œì§€ëŠ” CSSì—ì„œ p íƒœê·¸ ìŠ¤íƒ€ì¼ì„ ì¡ê³  ìˆìœ¼ë¯€ë¡œ p íƒœê·¸ë¡œ ê°ì‹¸ì¤Œ
            st.markdown(f"<p>{message['content']}</p>", unsafe_allow_html=True)

# ğŸš€ ìºì‹±ëœ í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš©ìœ¼ë¡œ ì†ë„ ê°œì„ 
def get_context(query_text):
    try:
        client = get_qdrant_client()
        embeddings = get_embeddings()
        query_vector = embeddings.embed_query(query_text)
        response = client.query_points(collection_name=COLLECTION_NAME, query=query_vector, limit=1, with_payload=True)
        if response.points:
            payload = response.points[0].payload.get("content", {})
            return f"ìƒí™©: {payload.get('situation_summary')}\nì¡°ì–¸: {payload.get('key_advice')}"
    except: return None
    return None

if prompt := st.chat_input("í•˜íŠ¸ ë°•ì‚¬ë‹˜ì—ê²Œ ê³ ë¯¼ì„ ë‚˜ëˆ ë³´ì„¸ìš”..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(f"<p>{prompt}</p>", unsafe_allow_html=True)

    with st.chat_message("assistant"):
        col_char, col_txt = st.columns([1, 4])
        with col_char: char_container = st.empty()
        with col_txt: msg_container = st.empty()
        full_response = ""
        chat_mouth_cycle = itertools.cycle(["assets/heart_o.png", "assets/heart_a.png", "assets/heart_closed.png"])
        
        # [ì˜ë„ íŒë³„ ë¡œì§ - ì¼ìƒëŒ€í™” vs RAG ìƒë‹´ êµ¬ë¶„]
        intent_llm = ChatOpenAI(model="gpt-4o-mini", openai_api_key=OPENAI_API_KEY, temperature=0)
        intent_prompt = f"""ë‹¤ìŒ ì‚¬ìš©ì ì…ë ¥ì„ ë¶„ì„í•´ì„œ 'ìƒë‹´' ë˜ëŠ” 'ì¼ìƒ' ì¤‘ í•˜ë‚˜ë¡œë§Œ ë‹µí•˜ì„¸ìš”.

[ë¶„ë¥˜ ê¸°ì¤€]
- ìƒë‹´: ì—°ì•  ê³ ë¯¼, ê°ì •ì  ë¬¸ì œ, ê´€ê³„ ê°ˆë“±, ì´ë³„, ì§ì‚¬ë‘, ì¸, ë°ì´íŠ¸, ê²°í˜¼ ê³ ë¯¼ ë“± ì—°ì• /ê´€ê³„ ê´€ë ¨ ìƒë‹´ì´ í•„ìš”í•œ ê²½ìš°
- ì¼ìƒ: ì¸ì‚¬ë§, ì•ˆë¶€, ë‚ ì”¨, ì¡ë‹´, í•˜íŠ¸ë°•ì‚¬ì— ëŒ€í•œ ì§ˆë¬¸, ë‹¨ìˆœ ëŒ€í™” ë“± ìƒë‹´ì´ í•„ìš” ì—†ëŠ” ê²½ìš°

ì‚¬ìš©ì ì…ë ¥: "{prompt}"
ë¶„ë¥˜:"""
        intent_check = intent_llm.invoke(intent_prompt).content.strip()
        
        is_counseling = "ìƒë‹´" in intent_check
        
        if is_counseling:
            # ğŸ” RAG ê¸°ë°˜ ì—°ì•  ìƒë‹´ ëª¨ë“œ
            context = get_context(prompt)
            system_prompt = """ë‹¹ì‹ ì€ ì—°ì•  ìƒë‹´ ì „ë¬¸ê°€ 'í•˜íŠ¸ ë°•ì‚¬'ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ì—°ì•  ê³ ë¯¼ì— ëŒ€í•´ ì œê³µëœ [ì°¸ê³  ì‚¬ë¡€]ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë”°ëœ»í•˜ê³  ê³µê°ì ì¸ ìƒë‹´ì„ í•´ì£¼ì„¸ìš”.
ë‹µë³€ì€ ì¡´ëŒ“ë§ë¡œ í•˜ê³ , êµ¬ì²´ì ì´ê³  ì‹¤ì§ˆì ì¸ ì¡°ì–¸ì„ ì œê³µí•˜ì„¸ìš”."""
            if context:
                user_content = f"[ì‚¬ìš©ì ê³ ë¯¼]\n{prompt}\n\n[ì°¸ê³  ì‚¬ë¡€]\n{context}"
            else:
                user_content = f"[ì‚¬ìš©ì ê³ ë¯¼]\n{prompt}\n\n(ì°¸ê³  ì‚¬ë¡€ ì—†ìŒ - ì¼ë°˜ì ì¸ ìƒë‹´ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”)"
        else:
            # ğŸ’¬ ì¼ìƒ ëŒ€í™” ëª¨ë“œ (RAG ì‚¬ìš© ì•ˆí•¨)
            system_prompt = """ë‹¹ì‹ ì€ ì¹œê·¼í•˜ê³  ë‹¤ì •í•œ 'í•˜íŠ¸ ë°•ì‚¬'ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì™€ í¸ì•ˆí•˜ê²Œ ì¼ìƒ ëŒ€í™”ë¥¼ ë‚˜ëˆ„ì„¸ìš”. ìœ ë¨¸ëŸ¬ìŠ¤í•˜ê³  ë”°ëœ»í•œ ë§íˆ¬ë¡œ ëŒ€í™”í•´ì£¼ì„¸ìš”.
ì—°ì•  ìƒë‹´ì´ í•„ìš”í•˜ë©´ ì–¸ì œë“  ë¬¼ì–´ë³´ë¼ê³  ì¹œì ˆí•˜ê²Œ ì•ˆë‚´í•´ì£¼ì„¸ìš”."""
            user_content = prompt

        history = []
        for m in st.session_state.messages[-5:]:
            if m["role"] == "user": history.append(HumanMessage(content=m["content"]))
            else: history.append(AIMessage(content=m["content"]))
        
        llm = ChatOpenAI(model="gpt-4o", openai_api_key=OPENAI_API_KEY, streaming=True)
        messages = [SystemMessage(content=system_prompt)] + history + [HumanMessage(content=user_content)]

        for chunk in llm.stream(messages):
            full_response += (chunk.content or "")
            char_container.image(next(chat_mouth_cycle), width=120)
            msg_container.markdown(f"<p>{full_response}â–Œ</p>", unsafe_allow_html=True)
            # time.sleep ì œê±°ë¡œ ìŠ¤íŠ¸ë¦¬ë° ì†ë„ ê°œì„ 

        char_container.image("assets/heart_closed.png", width=120)
        msg_container.markdown(f"<p>{full_response}</p>", unsafe_allow_html=True)
    
    st.session_state.messages.append({"role": "assistant", "content": full_response})