import os
import sys
import pandas as pd
from datasets import Dataset
from ragas import evaluate
from ragas.metrics import faithfulness, answer_relevancy
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI, OpenAIEmbeddings

# ===============================
# Ragas Wrapper (ë²„ì „ í˜¸í™˜)
# ===============================
try:
    from ragas.llms import LangchainLLMWrapper
    from ragas.embeddings import LangchainEmbeddingsWrapper
    USE_WRAPPER = True
except ImportError:
    USE_WRAPPER = False
    print("â„¹ï¸ Ragas LangchainWrapper not found. Using direct objects.")

# ===============================
# ê²½ë¡œ ì„¤ì •
# ===============================
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from retrieve_test import get_rag_response

# ===============================
# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
# ===============================
load_dotenv()

# ======================================================
# ğŸ”¥ í‰ê°€ ì „ìš© Context ì¬êµ¬ì„± í•¨ìˆ˜ (í•µì‹¬)
# ======================================================
def build_evaluation_context(payload) -> str:
    """
    payloadê°€
    - dict(Qdrant payload) ì´ë©´ â†’ êµ¬ì¡°í™” context ì¬êµ¬ì„±
    - str(ì´ë¯¸ í…ìŠ¤íŠ¸) ì´ë©´ â†’ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    """

    # âœ… ì´ë¯¸ ë¬¸ìì—´ì´ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜ (ê°€ì¥ ì¤‘ìš”)
    if isinstance(payload, str):
        return payload

    # âœ… dictì¼ ë•Œë§Œ êµ¬ì¡° ë¶„í•´
    retrieval = payload.get("retrieval", {})
    content = payload.get("content", {})
    context_meta = payload.get("context", {})

    parts = []

    if "situation_summary" in content:
        parts.append(
            f"ì—°ì•  ìƒí™© ìš”ì•½: {content['situation_summary']}"
        )

    if "core_conflict" in content:
        parts.append(
            f"í•µì‹¬ ê°ˆë“±: {content['core_conflict']}"
        )

    emotions = retrieval.get("emotion")
    if emotions:
        parts.append(
            f"ì£¼ìš” ê°ì •: {', '.join(emotions)}"
        )

    key_advice = content.get("key_advice")
    if key_advice:
        parts.append(
            "ì£¼ìš” ì¡°ì–¸: " + " ".join(key_advice)
        )

    do_list = content.get("do")
    if do_list:
        parts.append(
            "ê¶Œì¥ í–‰ë™: " + " ".join(do_list)
        )

    dont_list = content.get("dont")
    if dont_list:
        parts.append(
            "í”¼í•´ì•¼ í•  í–‰ë™: " + " ".join(dont_list)
        )

    return "\n".join(parts)


# ======================================================
# ë©”ì¸ í‰ê°€ ë¡œì§
# ======================================================
def run_evaluation():

    # ===============================
    # í‰ê°€ìš© ì§ˆë¬¸
    # ===============================
    test_questions = [
        "ì—¬ìì¹œêµ¬ì™€ ì—°ë½ ë¬¸ì œë¡œ ìì£¼ ì‹¸ì›Œ. ë‚´ê°€ ë„ˆë¬´ ì§‘ì°©í•˜ëŠ” ê±¸ê¹Œ?",
        "ì¸ íƒ€ëŠ” ì‚¬ëŒì´ ì¹´í†¡ ë‹µì¥ì´ ë„ˆë¬´ ëŠë ¤. ì´ê±° ê·¸ë¦°ë¼ì´íŠ¸ ë§ì•„?",
    ]

    results = {
        "question": [],
        "answer": [],
        "contexts": [],
    }

    print("ğŸš€ [RAG íŒŒì´í”„ë¼ì¸] í‰ê°€ ë°ì´í„° ìƒì„± ì¤‘...")

    for q in test_questions:
        print(f"\nğŸ“ ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘: {q}")

        response = get_rag_response(q, prompt_file="prompt.md")

        if not response:
            print(f"âŒ ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {q}")
            continue

        # ì§ˆë¬¸ / ë‹µë³€
        results["question"].append(response["query"])
        results["answer"].append(response["answer"])

        # ===============================
        # ğŸ”¥ í‰ê°€ ì „ìš© Context ë³€í™˜
        # ===============================
        evaluation_contexts = []

        for payload in response["contexts"]:
            eval_context = build_evaluation_context(payload)
            evaluation_contexts.append(eval_context)

        # RAGASëŠ” List[str] í˜•íƒœë¥¼ ê¸°ëŒ€
        results["contexts"].append(evaluation_contexts)

        print(f"âœ… ë‹µë³€:\n{response['answer']}")
        print("ğŸ“š í‰ê°€ìš© Context:")
        for ctx in evaluation_contexts:
            print(ctx)
            print("-" * 50)

    if not results["question"]:
        print("âš ï¸ í‰ê°€í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ===============================
    # Dataset ìƒì„±
    # ===============================
    dataset = Dataset.from_dict(results)

    print("\nğŸ“Š [RAGAS] í‰ê°€ ì‹œì‘...")

    metrics = [
        faithfulness,
        answer_relevancy,
    ]

    # ===============================
    # LLM / Embeddings
    # ===============================
    llm = ChatOpenAI(model="gpt-4o")
    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")

    if USE_WRAPPER:
        eval_llm = LangchainLLMWrapper(llm)
        eval_embeddings = LangchainEmbeddingsWrapper(embeddings)
    else:
        eval_llm = llm
        eval_embeddings = embeddings

    try:
        evaluation_result = evaluate(
            dataset=dataset,
            metrics=metrics,
            llm=eval_llm,
            embeddings=eval_embeddings,
        )

        print("\nğŸ† í‰ê°€ ê²°ê³¼ ìš”ì•½:")
        print(evaluation_result)

        df = evaluation_result.to_pandas()

        print("\nğŸ“„ ìƒì„¸ ê²°ê³¼:")
        print(f"Columns: {df.columns.tolist()}")

        # ì»¬ëŸ¼ ë³´ì •
        if "user_input" in df.columns and "question" not in df.columns:
            df["question"] = df["user_input"]

        display_cols = [
            c for c in ["question", "answer", "faithfulness", "answer_relevancy"]
            if c in df.columns
        ]

        print(df[display_cols])

        # ===============================
        # ê²°ê³¼ ì €ì¥
        # ===============================
        output_txt = "rag_evaluation_results.txt"
        with open(output_txt, "w", encoding="utf-8") as f:
            f.write(df.to_string(index=False))

        print(f"\nğŸ’¾ ê²°ê³¼ê°€ '{output_txt}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        print(f"ğŸ”¥ í‰ê°€ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

# ======================================================
# Entry Point
# ======================================================
if __name__ == "__main__":
    run_evaluation()
