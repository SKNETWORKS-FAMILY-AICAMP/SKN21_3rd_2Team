import os
import sys

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ sys.pathì— ì¶”ê°€í•˜ì—¬ ëª¨ë“ˆ ì¸ì‹ ë¬¸ì œ í•´ê²°
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(os.path.dirname(current_dir))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from rag.config import Config
from qdrant_client import QdrantClient
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

import os
from langchain_openai import OpenAIEmbeddings
from langchain_core.documents import Document
from sentence_transformers import CrossEncoder
from rank_bm25 import BM25Okapi

import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

from dotenv import load_dotenv
load_dotenv()

QDRANT_URL = os.getenv('QDRANT_URL')
QDRANT_API_KEY = os.getenv('QDRANT_API_KEY')
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')

COLLECTION_NAME = "love_counseling_db"
reranker = CrossEncoder("BAAI/bge-reranker-v2-m3")

def bm25_search(query, corpus_docs, k=3):
    tokenized = [d.page_content.split() for d in corpus_docs]
    bm25 = BM25Okapi(tokenized)

    scores = bm25.get_scores(query.split())
    topk_idx = np.argsort(scores)[::-1][:k]

    return [corpus_docs[i] for i in topk_idx]


def mmr(query_vec, doc_vecs, docs, k, lambda_mult=0.5):
    selected = []
    selected_idx = []

    sim_to_query = cosine_similarity([query_vec], doc_vecs)[0]
    sim_between_docs = cosine_similarity(doc_vecs)

    for _ in range(k):
        if len(selected_idx) == 0:
            idx = int(np.argmax(sim_to_query))
        else:
            remaining = list(set(range(len(docs))) - set(selected_idx))
            mmr_scores = []

            for i in remaining:
                diversity = max(sim_between_docs[i][j] for j in selected_idx)
                score = lambda_mult * sim_to_query[i] - (1 - lambda_mult) * diversity
                mmr_scores.append((score, i))

            idx = max(mmr_scores)[1]

        selected_idx.append(idx)
        selected.append(docs[idx])

    return selected


def rerank(query, docs, top_n=3):
    pairs = [[query, d.page_content] for d in docs]
    scores = reranker.predict(pairs)

    ranked = sorted(zip(scores, docs), key=lambda x: x[0], reverse=True)
    return [d for _, d in ranked[:top_n]]

def build_text_from_payload(payload: dict) -> str:
    content = payload.get("content", {})

    parts = []

    if "situation_summary" in content:
        parts.append(f"ìƒí™©: {content['situation_summary']}")

    if "core_conflict" in content:
        parts.append(f"ê°ˆë“±: {content['core_conflict']}")

    if "key_advice" in content:
        parts.append("í•µì‹¬ ì¡°ì–¸: " + " ".join(content["key_advice"]))

    if "do" in content:
        parts.append("ê¶Œì¥ í–‰ë™: " + " ".join(content["do"]))

    if "dont" in content:
        parts.append("í”¼í•´ì•¼ í•  í–‰ë™: " + " ".join(content["dont"]))

    return "\n".join(parts)

def pretty_print_docs(docs):
    print("\n====== Retrieval Results ======\n")

    for i, d in enumerate(docs, 1):
        print(f"[{i}] --------------------------")

        meta = d.metadata.get("retrieval", {})
        context = d.metadata.get("context", {})

        print("ì£¼ì œ:", meta.get("main_topic"))
        print("ë‹¨ê³„:", meta.get("relationship_stage"))
        print("ê°ì •:", meta.get("emotion"))

        print("ìœ„í—˜ë„:", context.get("risk_level"))
        print("ìŠ¤íƒ€ì¼:", context.get("advisor_style"))

        print("\nSummary:")
        print(d.page_content[:400], "...\n")


def operate_retriever(query_text, k=3, verbose=False):
    # verbose ëª¨ë“œì—ì„œë§Œ ì§ˆì˜ ë‚´ìš©ì„ ì¶œë ¥í•´ í„°ë¯¸ë„ ì¤‘ë³µ ì¶œë ¥ì„ ë°©ì§€
    if verbose:
        print(f"[retriever] query: {query_text}")

    try:
        # ğŸš€ 1. Query Rewriting ì ìš© (ê²€ìƒ‰ìš© ì¿¼ë¦¬ ìƒì„±)

        client = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)
        embeddings = OpenAIEmbeddings(model="text-embedding-3-small", openai_api_key=OPENAI_API_KEY)
        
        # ğŸš€ 2. ì¬ì‘ì„±ëœ ì¿¼ë¦¬ë¡œ ë²¡í„° ìƒì„±
        query_vector = np.array(embeddings.embed_query(query_text))

        resp = client.query_points(
            collection_name=COLLECTION_NAME,
            query=query_vector.tolist(),
            limit=20,
            with_payload=True,
            with_vectors=True,
        )

        docs = []
        vectors = []
        for p in resp.points:
            payload = p.payload or {}
            text = build_text_from_payload(payload)
            if not text.strip():
                continue

            docs.append(Document(page_content=text,
                    metadata={"retrieval": payload.get("retrieval"),
                              "context": payload.get("context"),
                              "id": p.id,
                              "score": p.score}))
            vectors.append(p.vector)

        if len(docs) == 0:
            print("Qdrantì—ì„œ í…ìŠ¤íŠ¸ payloadë¥¼ ì°¾ì§€ ëª»í•¨.")
            return []

        mmr_docs = mmr(query_vector, np.array(vectors), docs, k=k)

        # bm25_docs = bm25_search(query_text, docs, k=10)
        # hybrid_docs = mmr_docs + bm25_docs
        
        # pairs = [[query_text, d.page_content] for d in hybrid_docs]
        # scores = reranker.predict(pairs)

        # ranked = sorted(zip(scores, hybrid_docs), key=lambda x: x[0], reverse=True)
        
        # if verbose:
        #     print(f"Developer Mode:")
        #     print("=" * 50)
        #     print(f"[retriever] ranked: {ranked}")
        #     print(f"len(ranked): {len(ranked)}")
        # final_docs = [d for _, d in ranked[:k]]
        return mmr_docs

    except Exception as e:
        print(f"Error: {e}")
        return None







