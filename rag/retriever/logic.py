from rag.config import Config
from qdrant_client import QdrantClient

import os
from langchain_openai import OpenAIEmbeddings
from langchain_core.documents import Document
from sentence_transformers import CrossEncoder
from rank_bm25 import BM25Okapi

import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

from dotenv import load_dotenv
load_dotenv()

QDRANT_URL = os.getenv('QDRANT_URL')
QDRANT_API_KEY = os.getenv('QDRANT_API_KEY')
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')

COLLECTION_NAME = "love_counseling_db"
reranker = CrossEncoder("BAAI/bge-reranker-v2-m3")


def bm25_search(query, corpus_docs, k=3):
    tokenized = [d.page_content.split() for d in corpus_docs]
    bm25 = BM25Okapi(tokenized)

    scores = bm25.get_scores(query.split())
    topk_idx = np.argsort(scores)[::-1][:k]

    return [corpus_docs[i] for i in topk_idx]


def mmr(query_vec, doc_vecs, docs, k, lambda_mult=0.5):
    selected = []
    selected_idx = []

    sim_to_query = cosine_similarity([query_vec], doc_vecs)[0]
    sim_between_docs = cosine_similarity(doc_vecs)

    for _ in range(k):
        if len(selected_idx) == 0:
            idx = int(np.argmax(sim_to_query))
        else:
            remaining = list(set(range(len(docs))) - set(selected_idx))
            mmr_scores = []

            for i in remaining:
                diversity = max(sim_between_docs[i][j] for j in selected_idx)
                score = lambda_mult * sim_to_query[i] - (1 - lambda_mult) * diversity
                mmr_scores.append((score, i))

            idx = max(mmr_scores)[1]

        selected_idx.append(idx)
        selected.append(docs[idx])

    return selected


def rerank(query, docs, top_n=3):
    pairs = [[query, d.page_content] for d in docs]
    scores = reranker.predict(pairs)

    ranked = sorted(zip(scores, docs), key=lambda x: x[0], reverse=True)
    return [d for _, d in ranked[:top_n]]

def build_text_from_payload(payload: dict) -> str:
    content = payload.get("content", {})

    parts = []

    if "situation_summary" in content:
        parts.append(f"ìƒí™©: {content['situation_summary']}")

    if "core_conflict" in content:
        parts.append(f"ê°ˆë“±: {content['core_conflict']}")

    if "key_advice" in content:
        parts.append("í•µì‹¬ ì¡°ì–¸: " + " ".join(content["key_advice"]))

    if "do" in content:
        parts.append("ê¶Œì¥ í–‰ë™: " + " ".join(content["do"]))

    if "dont" in content:
        parts.append("í”¼í•´ì•¼ í•  í–‰ë™: " + " ".join(content["dont"]))

    return "\n".join(parts)

def pretty_print_docs(docs):
    print("\n====== Retrieval Results ======\n")

    for i, d in enumerate(docs, 1):
        print(f"[{i}] --------------------------")

        meta = d.metadata.get("retrieval", {})
        context = d.metadata.get("context", {})

        print("ì£¼ì œ:", meta.get("main_topic"))
        print("ë‹¨ê³„:", meta.get("relationship_stage"))
        print("ê°ì •:", meta.get("emotion"))

        print("ìœ„í—˜ë„:", context.get("risk_level"))
        print("ìŠ¤íƒ€ì¼:", context.get("advisor_style"))

        print("\nSummary:")
        print(d.page_content[:400], "...\n")


def operate_retriever(query_text, k=3):
    print(f"--- ğŸ” ì§ˆë¬¸: '{query_text}' ---")

    try:
        client = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)
        embeddings = OpenAIEmbeddings(model="text-embedding-3-small", openai_api_key=OPENAI_API_KEY)
        query_vector = np.array(embeddings.embed_query(query_text))

        resp = client.query_points(
            collection_name=COLLECTION_NAME,
            query=query_vector.tolist(),
            limit=40,
            with_payload=True,
            with_vectors=True,
        )

        docs = []
        vectors = []
        for p in resp.points:
            payload = p.payload or {}
            text = build_text_from_payload(payload)
            if not text.strip():
                continue

            docs.append(Document(page_content=text,
                    metadata={"retrieval": payload.get("retrieval"),
                              "context": payload.get("context"),"id": p.id,"score": p.score}))
            vectors.append(p.vector)

        if len(docs) == 0:
            print("Qdrantì—ì„œ í…ìŠ¤íŠ¸ payloadë¥¼ ì°¾ì§€ ëª»í•¨.")
            return []

        mmr_docs = mmr(query_vector, np.array(vectors), docs, k=12)

        bm25_docs = bm25_search(query_text, docs, k=12)
        hybrid_docs = mmr_docs + bm25_docs

        pairs = [[query_text, d.page_content] for d in hybrid_docs]
        scores = reranker.predict(pairs)

        ranked = sorted(zip(scores, hybrid_docs), key=lambda x: x[0], reverse=True)
        final_docs = [d for _, d in ranked[:k]]
        return final_docs



    except Exception as e:
        print(f"Error: {e}")
        return None


query = "ì²«ì‚¬ë‘ì´ ê³„ì† ìƒê°ë‚˜ì„œ ìƒˆë¡œìš´ ì‚¬ëŒì„ ëª» ë§Œë‚˜ê² ì–´ìš”"
docs = operate_retriever(query, k=3)
pretty_print_docs(docs)


def get_retriever(vector_store, search_type="similarity", k=4):
    """
    íŒ€ì› 3ì´ êµ¬í˜„í•  ê²€ìƒ‰ ë¡œì§ (ìœ ì‚¬ë„ ê²€ìƒ‰, MMR ë“±)
    """




def run_retriever_example(query_text, k=3):
    """
    Retriever ë² ì´ìŠ¤ ë¡œì§
    """
    print(f"--- ğŸ” ì§ˆë¬¸: '{query_text}' ---")

    try:
        # 1. Qdrant / Embedding ê°ì²´ ìƒì„±
        client = QdrantClient(
            url=Config.QDRANT_URL,
            api_key=Config.QDRANT_API_KEY
        )

        embeddings = OpenAIEmbeddings(
            model="text-embedding-3-small",
            openai_api_key=Config.OPENAI_API_KEY
        )

        # 2. ì§ˆë¬¸ â†’ ë²¡í„°
        query_vector = embeddings.embed_query(query_text)

        # 3. ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰
        response = client.query_points(
            collection_name=Config.COLLECTION_NAME,
            query=query_vector,
            limit=k,
            with_payload=True
        )

        return response  # QueryResponse ë°˜í™˜

    except Exception as e:
        print(f"ğŸ”¥ ì—ëŸ¬ ë°œìƒ: {e}")
        return None

def print_retriever_results(query_text, k=3):
    """
    Retriever ê²°ê³¼ë¥¼ ìƒì„¸í•˜ê²Œ í„°ë¯¸ë„ì— ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜
    Args:
        query_text: ì§ˆë¬¸ í…ìŠ¤íŠ¸
        k: ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜
    """
    # run_retriever_exampleë¡œ ê²€ìƒ‰ ìˆ˜í–‰
    response = run_retriever_example(query_text, k=k)
    
    if not response or not response.points:
        print("âŒ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"\nâœ… ì´ {len(response.points)}ê°œì˜ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.\n")
    print("=" * 80)
    
    for i, point in enumerate(response.points, 1):
        payload = point.payload or {}
        content_box = payload.get("content", {})
        
        # ë¬¸ì„œ ì •ë³´ ì¶”ì¶œ
        situation = content_box.get("situation_summary", "ë‚´ìš© ì—†ìŒ")
        advice = content_box.get("key_advice", [])
        
        # advice ë¦¬ìŠ¤íŠ¸ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
        if isinstance(advice, list):
            advice_str = "\n   â€¢ ".join(advice) if advice else "ì¡°ì–¸ ì—†ìŒ"
        else:
            advice_str = str(advice)
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"\nğŸ“„ ë¬¸ì„œ #{i} (ìœ ì‚¬ë„ ì ìˆ˜: {point.score:.4f})")
        print("-" * 80)
        print(f"ğŸ“Œ ìƒí™© ìš”ì•½:")
        print(f"   {situation}")
        print(f"\nğŸ’¡ í•µì‹¬ ì¡°ì–¸:")
        print(f"   â€¢ {advice_str}")
        
        # ì¶”ê°€ ë©”íƒ€ë°ì´í„°ê°€ ìˆë‹¤ë©´ ì¶œë ¥
        if payload.get("metadata"):
            print(f"\nğŸ“Š ì¶”ê°€ ì •ë³´: {payload.get('metadata')}")
        
        # ë””ë²„ê¹…ìš© - content_boxê°€ ë¹„ì–´ìˆìœ¼ë©´ ì „ì²´ payload ì¶œë ¥
        if not content_box:
            print(f"\nâš ï¸ [ë””ë²„ê¹…] ì „ì²´ Payload: {payload}")
        
        print("=" * 80)
    
    print()
    return response





